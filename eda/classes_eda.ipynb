{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import yaml\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .env variables\n",
    "load_dotenv()\n",
    "\n",
    "data_dir = os.getenv('DATA_DIR')\n",
    "final_model_dir = os.getenv('MODEL_DIR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_yaml_file_paths(data_dir: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Retrieve the paths to all 'data.yaml' files within subdirectories of a given directory.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): The root directory containing subdirectories to search for 'data.yaml' files.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of file paths to 'data.yaml' files found within the subdirectories.\n",
    "    \"\"\"\n",
    "    # Verify the directory exists\n",
    "    if not os.path.exists(data_dir):\n",
    "        raise FileNotFoundError(f\"The directory '{data_dir}' does not exist.\")\n",
    "    \n",
    "    # Ensure the input path is a directory\n",
    "    if not os.path.isdir(data_dir):\n",
    "        raise ValueError(f\"The path '{data_dir}' is not a directory.\")\n",
    "\n",
    "    yaml_files = []\n",
    "    \n",
    "    # Iterate through each subdirectory in the given directory\n",
    "    for dir_name in os.listdir(data_dir):\n",
    "        directory = os.path.join(data_dir, dir_name)\n",
    "        \n",
    "        if os.path.isdir(directory):\n",
    "            for filename in os.listdir(directory):\n",
    "                if filename == 'data.yaml':\n",
    "                    yaml_path = os.path.join(directory, filename)\n",
    "                    yaml_files.append(yaml_path)\n",
    "\n",
    "    return yaml_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yaml_data(yaml_files: List[str]) -> List:\n",
    "    \"\"\"\n",
    "    Load data from each yaml file\n",
    "\n",
    "    Args:\n",
    "        yaml_files: list of yaml file paths\n",
    "    Returns:\n",
    "        List of unique classes from all data.yaml file in data directory\n",
    "    \"\"\"\n",
    "    loaded_yaml_data = []\n",
    "    # Loop through each file path and load the YAML content\n",
    "    for file_path in yaml_files:\n",
    "        with open(file_path, 'r') as file:\n",
    "            yaml_data = yaml.safe_load(file)\n",
    "            # print(yaml_data['names'])\n",
    "            loaded_yaml_data.extend(yaml_data['names'])\n",
    "    classes_list = list(set(loaded_yaml_data))\n",
    "    classes_list.sort()\n",
    "    return classes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_class_dict(classes_list: List[str]) -> Dict[int, str]:\n",
    "    \"\"\"\n",
    "    Converts a list of classes into a dictionary of indexed pairs.\n",
    "\n",
    "    Args: \n",
    "        classes_list (List[str]): List of unique classes to create the dictionary.\n",
    "\n",
    "    Returns:\n",
    "        Dict[int, str]: A dictionary where keys are indices and values are class names.\n",
    "    \"\"\"\n",
    "    classes_dict = dict()\n",
    "    for i, cls in enumerate(classes_list):\n",
    "        classes_dict[i] = cls\n",
    "    return classes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_yaml_file(classes_dict: Dict[int, str], output_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Creates a YAML file with the specified structure, where the 'nc' and 'names' \n",
    "    fields are derived from the provided classes_dict.\n",
    "\n",
    "    Args:\n",
    "        classes_dict (Dict[int, str]): A dictionary where keys are indices and values are class names.\n",
    "        output_path (str): The file path where the YAML file will be saved.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    nc = len(classes_dict)\n",
    "    \n",
    "    names = [classes_dict[i] for i in range(nc)]\n",
    "    \n",
    "    data = {\n",
    "        'train': '../train/images',\n",
    "        'val': '../valid/images',\n",
    "        'test': '../test/images',\n",
    "        'nc': nc,\n",
    "        'names': names\n",
    "    }\n",
    "    \n",
    "    with open(output_path, 'w') as yaml_file:\n",
    "        yaml.dump(data, yaml_file, default_flow_style=False)\n",
    "\n",
    "    print(f\"YAML file created at: {output_path}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(data_dir: str) -> None:\n",
    "    \"\"\"\n",
    "    Main function for program runs all functions in sequence\n",
    "    \"\"\"\n",
    "    yaml_files = get_yaml_file_paths(data_dir=data_dir)\n",
    "    classes_list = get_yaml_data(yaml_files)\n",
    "    classes_dict = create_class_dict(classes_list)\n",
    "    create_yaml_file(classes_dict, final_model_dir)\n",
    "    print(classes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'almond butter', 1: 'apple', 2: 'avocado', 3: 'bacon', 4: 'baking soda', 5: 'balsamic vinaigrette', 6: 'balsamic vinegar', 7: 'barbecue sauce', 8: 'basil', 9: 'basil pesto', 10: 'beans', 11: 'bitter gaurd', 12: 'black beans', 13: 'black pepper', 14: 'bread', 15: 'bringal', 16: 'brown onion', 17: 'buffalo sauce', 18: 'butter', 19: 'cabbage', 20: 'cajun', 21: 'cake', 22: 'candy', 23: 'canola oil', 24: 'capsicum', 25: 'carrots', 26: 'cauliflower', 27: 'cayenne pepper', 28: 'cereal', 29: 'cheese', 30: 'chicken', 31: 'chicken stock', 32: 'chickpeas', 33: 'chillies', 34: 'chips', 35: 'chocolate', 36: 'cinnamon', 37: 'coffee', 38: 'coriander', 39: 'corn', 40: 'cucumber', 41: 'cumin', 42: 'egg', 43: 'fish', 44: 'flour', 45: 'garlic', 46: 'ginger', 47: 'gnocchi', 48: 'grapes', 49: 'hoison sauce', 50: 'honey', 51: 'hot sauce', 52: 'italian herbs', 53: 'jalapeno', 54: 'jam', 55: 'juice', 56: 'ketchup', 57: 'kiwi', 58: 'kumara', 59: 'laksa paste', 60: 'lemon', 61: 'lettuce', 62: 'lime juice', 63: 'milk', 64: 'muesli bars', 65: 'mustard', 66: 'noodles', 67: 'nuts', 68: 'oil', 69: 'okra', 70: 'olive oil', 71: 'onion', 72: 'onion powder', 73: 'orange', 74: 'oregano', 75: 'paprika', 76: 'pasta', 77: 'potato', 78: 'pumpkin', 79: 'red onion', 80: 'red wine vinegar', 81: 'rice', 82: 'salad', 83: 'salmon', 84: 'salsa', 85: 'salt', 86: 'sesame oil', 87: 'soda', 88: 'soy sauce', 89: 'spices', 90: 'sriracha', 91: 'sugar', 92: 'sweet chili sauce', 93: 'syrup', 94: 'tartare sauce', 95: 'tea', 96: 'tomato', 97: 'tomato puree', 98: 'tomato sauce', 99: 'tomato_sauce', 100: 'vanilla', 101: 'vegetable oil', 102: 'vinegar', 103: 'water', 104: 'watermelon'}\n"
     ]
    }
   ],
   "source": [
    "main(data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
